{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkskTZ7J8--_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pnp-oO5g9Ws8"
      },
      "outputs": [],
      "source": [
        "\n",
        "%pip install CRPS\n",
        "%pip install torchgeo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taR19He7ZjLW"
      },
      "outputs": [],
      "source": [
        " \n",
        "from pathlib import Path\n",
        "import sys\n",
        "!sudo apt-get install unzip\n",
        "base = Path('/content/drive/MyDrive/ML/2023/conv_strat_dataset')\n",
        "sys.path.append(str(base))\n",
        "\n",
        "zip_path = base/\"lwe_dataset_010322.zip\"\n",
        "\n",
        "\n",
        "!cp \"{zip_path}\" .\n",
        "\n",
        "!unzip -q lwe_dataset_010322.zip -d \"/content\"\n",
        "\n",
        "!rm lwe_dataset_010322.zip\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCa50HYsDsm"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe8ibXtZ87sM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "from datetime import date\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "# import wandb\n",
        "# import CRPS.CRPS as pscore\n",
        "\n",
        "\n",
        "from prec_dataset import RadarPrecipitationSequence\n",
        "from radar_transforms import radar_transform\n",
        "from plotting_funcs import show_sequence\n",
        "from radar_transforms import radar_transform, reverse_transform, conditional_embedding_transform\n",
        "from fdp import fdp_sample, get_named_beta_schedule\n",
        "from unet_refr_emb import UNet_embedding\n",
        "from loss import loss_fn\n",
        "from sampler import sample_plot_image\n",
        "from helper_module import get_random_test_seq, get_CRPS_sequence\n",
        "from calc_metrics import get_CRPS\n",
        "\n",
        "config = dict(\n",
        "    img_out_size=64,\n",
        "    rgb_grayscale=1,\n",
        "    sequence_length=4,\n",
        "    max_prec_val=3.4199221045419974,\n",
        "    prediction_time_step_ahead=1,\n",
        "    frames_to_predict=1,\n",
        "    num_cond_frames=3,\n",
        "    epochs=51,\n",
        "    batch_size=24,\n",
        "    lr=0.001,\n",
        "    T=300,\n",
        "    schedule=\"linear\",\n",
        "    root_dir=r\"/content/lwe_dataset\",\n",
        "    validate_on_convective = False,\n",
        "    plot_folder = \"/content/drive/MyDrive/ML/results/plots/2702_embedding_concat\"\n",
        ")\n",
        "\n",
        "plot_folder = config[\"plot_folder\"]\n",
        "with open(f'{plot_folder}/config.json', 'w') as fp:\n",
        "    json.dump(config, fp)\n",
        "\n",
        "betas = get_named_beta_schedule(\n",
        "    schedule_name=config[\"schedule\"], num_diffusion_timesteps=config[\"T\"]\n",
        ")\n",
        "T = config[\"T\"]\n",
        "if config[\"schedule\"] == \"linear\":\n",
        "    alphas = 1.0 - betas\n",
        "    alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "    alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "    sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
        "    sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "    sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
        "    posterior_variance = betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rqRgWcjsDso",
        "outputId": "4d7dbf37-7c36-4e99-c192-29de18cf170a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchgeo.models import resnet18, ResNet18_Weights\n",
        "\n",
        "weights = ResNet18_Weights.SENTINEL2_RGB_MOCO\n",
        "\n",
        "cond_emb_model = resnet18(weights=weights)\n",
        "cond_emb_model.to(device)\n",
        "cond_emb_model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gazouiXkO1Fv",
        "outputId": "26ab92d0-e683-4be9-f612-a44b6ce89bb5"
      },
      "outputs": [],
      "source": [
        "model = UNet_embedding(rgb_grayscale=1, num_cond_frames=3, device=device)\n",
        "model = model.to(device)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgmVVa4-87sQ"
      },
      "source": [
        "### Define datasets and dataloader: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS2gqHvq87sR"
      },
      "outputs": [],
      "source": [
        "dataset_radar_sequence = RadarPrecipitationSequence(\n",
        "    root_dir=config[\"root_dir\"],\n",
        "    transform=radar_transform(max_prec_val=config[\"max_prec_val\"]),\n",
        "    emb_transform=conditional_embedding_transform(max_prec_val=config[\"max_prec_val\"]),\n",
        "    num_cond_frames=config[\"num_cond_frames\"],\n",
        "    frames_to_predict=config[\"frames_to_predict\"],\n",
        "    img_out_size=config[\"img_out_size\"],\n",
        "    prediction_time_step_ahead=config[\"prediction_time_step_ahead\"],\n",
        "    train_test_val = \"train\"\n",
        ")\n",
        "dataset_radar_sequence_val = RadarPrecipitationSequence(\n",
        "    root_dir=config[\"root_dir\"],\n",
        "    transform=radar_transform(max_prec_val=config[\"max_prec_val\"]),\n",
        "    emb_transform=conditional_embedding_transform(max_prec_val=config[\"max_prec_val\"]),\n",
        "    num_cond_frames=config[\"num_cond_frames\"],\n",
        "    frames_to_predict=config[\"frames_to_predict\"],\n",
        "    img_out_size=config[\"img_out_size\"],\n",
        "    prediction_time_step_ahead=config[\"prediction_time_step_ahead\"],\n",
        "    train_test_val = \"val\"\n",
        ")\n",
        "\n",
        "dataset_radar_sequence_val_CRPS = RadarPrecipitationSequence(\n",
        "    root_dir=config[\"root_dir\"],\n",
        "    transform=radar_transform(max_prec_val=config[\"max_prec_val\"]),\n",
        "    emb_transform=conditional_embedding_transform(max_prec_val=config[\"max_prec_val\"]),\n",
        "    num_cond_frames=config[\"num_cond_frames\"],\n",
        "    frames_to_predict=config[\"frames_to_predict\"],\n",
        "    img_out_size=config[\"img_out_size\"],\n",
        "    prediction_time_step_ahead=config[\"prediction_time_step_ahead\"],\n",
        "    train_test_val = \"val\",\n",
        "    center_crop = True\n",
        ")\n",
        "\n",
        "# dataset_radar_sequence_test = RadarPrecipitationSequence(\n",
        "#     root_dir=config[\"root_dir\"],\n",
        "#     transform=radar_transform(max_prec_val=config[\"max_prec_val\"]),\n",
        "#     emb_transform=conditional_embedding_transform(max_prec_val=config[\"max_prec_val\"]),\n",
        "#     num_cond_frames=config[\"num_cond_frames\"],\n",
        "#     frames_to_predict=config[\"frames_to_predict\"],\n",
        "#     img_out_size=config[\"img_out_size\"],\n",
        "#     prediction_time_step_ahead=config[\"prediction_time_step_ahead\"],\n",
        "#     train_test_val = \"test\"\n",
        "\n",
        "# )\n",
        "\n",
        "# dataset_radar_sequence_test = RadarPrecipitationSequence(root_dir=\"dataset_1000_five_seq\", transform= radar_transform(IMG_SIZE=img_out_size), output_img_size=img_out_size, train=False)\n",
        "dataloader = DataLoader(\n",
        "    dataset_radar_sequence,\n",
        "    batch_size=config[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "    dataset_radar_sequence_val,\n",
        "    batch_size=config[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        ")\n",
        "validation_dataloader_CRPS = DataLoader(\n",
        "    dataset_radar_sequence_val_CRPS,\n",
        "    batch_size=config[\"batch_size\"],\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEFxphfH87sS"
      },
      "source": [
        "### Random samples from dataset: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "hpeCC3cn87sS",
        "outputId": "f585ced1-8ff3-468a-df90-f494b7113f3b"
      },
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "    idx = np.random.randint(low=0, high=1000)\n",
        "    train_sample = dataset_radar_sequence.__getitem__(idx)\n",
        "\n",
        "    show_sequence(train_sample, 3, pred_ahead= config[\"prediction_time_step_ahead\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJWENxEg87sU"
      },
      "source": [
        "### Train Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdO3cHtg87sU",
        "outputId": "66474f84-fb94-4ea0-8496-04735c04a871"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "train_loss_list = []\n",
        "validation_loss_list = []\n",
        "avg_4_crps_mean = []\n",
        "avg_16_crps_mean = []\n",
        "max_4_crps_mean = []\n",
        "max_16_crps_mean = []\n",
        "\n",
        "avg_4_crps_std = []\n",
        "avg_16_crps_std = []\n",
        "max_4_crps_std = []\n",
        "max_16_crps_std = []\n",
        "\n",
        "\n",
        "crps_idx_list = [57,\n",
        " 460,\n",
        " 63,\n",
        " 203,\n",
        " 357,\n",
        " 164,\n",
        " 327,\n",
        " 470,\n",
        " 260,\n",
        " 161,\n",
        " 140,\n",
        " 404,\n",
        " 379,\n",
        " 451,\n",
        " 289,\n",
        " 79,\n",
        " 141,\n",
        " 76,\n",
        " 42,\n",
        " 47]\n",
        "\n",
        "\n",
        "\n",
        "best_val_score = 1\n",
        "for epoch in range(config[\"epochs\"]):\n",
        "    avg_epoch_train_loss = 0 \n",
        "    \n",
        "    for step, batch in enumerate(tqdm(dataloader)):\n",
        "        \n",
        "        batch_lwe = batch[0]\n",
        "        batch_lwe = batch_lwe.float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        t = torch.randint(0, config[\"T\"], (config[\"batch_size\"],), device=device).long()\n",
        "\n",
        "        conditional_imgs = batch[1]\n",
        "\n",
        "        imgs_to_model_training = batch_lwe\n",
        "        # imgs_to_model_training = imgs_to_model_training[:, None, :, :]\n",
        "        # print(f\"imgs_to_model_training.shape = {imgs_to_model_training.shape}\")\n",
        "        # print(f\"conditional_imgs.shape = {conditional_imgs.shape}\")\n",
        "        conditional_imgs = conditional_imgs.float()\n",
        "        conditional_imgs = conditional_imgs.to(device)\n",
        "        loss = loss_fn(\n",
        "            model=model,\n",
        "            x=imgs_to_model_training,\n",
        "            t=t,\n",
        "            device=device,\n",
        "            cond_emb_model = cond_emb_model,\n",
        "            sqrt_one_minus_alphas_cumprod=sqrt_one_minus_alphas_cumprod,\n",
        "            sqrt_alphas_cumprod=sqrt_alphas_cumprod,\n",
        "            condition=conditional_imgs,\n",
        "        )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        avg_epoch_train_loss += loss.item()\n",
        "        \n",
        "    avg_epoch_train_loss = avg_epoch_train_loss/(step+1)\n",
        "    \n",
        "    #get validation loss for same epoch\n",
        "    avg_epoch_val_loss = 0 \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for vstep, vbatch in enumerate(tqdm(validation_dataloader)):\n",
        "            batch_lwe = vbatch[0]\n",
        "            batch_lwe = batch_lwe.float()\n",
        "\n",
        "            t = torch.randint(0, config[\"T\"], (config[\"batch_size\"],), device=device).long()\n",
        "\n",
        "            conditional_imgs = vbatch[1]\n",
        "            imgs_to_model_training = batch_lwe\n",
        "            # print(f\"imgs_to_model_training.shape = {imgs_to_model_training.shape}\")\n",
        "            # print(f\"conditional_imgs.shape = {conditional_imgs.shape}\")\n",
        "            conditional_imgs = conditional_imgs.float()\n",
        "\n",
        "            conditional_imgs = conditional_imgs.to(device)\n",
        "            loss = loss_fn(\n",
        "                model=model,\n",
        "                x=imgs_to_model_training,\n",
        "                t=t,\n",
        "                device=device,\n",
        "                cond_emb_model = cond_emb_model,\n",
        "                sqrt_one_minus_alphas_cumprod=sqrt_one_minus_alphas_cumprod,\n",
        "                sqrt_alphas_cumprod=sqrt_alphas_cumprod,\n",
        "                condition=conditional_imgs,\n",
        "            )\n",
        "            avg_epoch_val_loss += loss.item()\n",
        "        \n",
        "        avg_epoch_val_loss = avg_epoch_val_loss/(vstep+1)\n",
        "        if avg_epoch_val_loss < best_val_score:\n",
        "            best_val_score = avg_epoch_val_loss\n",
        "            today = date.today()\n",
        "            torch.save(model.state_dict(), f\"{plot_folder}/{today}_epoch_{epoch}\")\n",
        "        \n",
        "        print(f\"Epoch {epoch} | Avg Train Loss: {avg_epoch_train_loss}, Avg Validation Loss: {avg_epoch_val_loss} \")\n",
        "        train_loss_list.append(avg_epoch_train_loss)\n",
        "        validation_loss_list.append(avg_epoch_val_loss)\n",
        "\n",
        "        \n",
        "    # if convective_crps:\n",
        "        # get_convective_test_seq()\n",
        "\n",
        "        # if epoch % 3 == 0:# and epoch > 0:\n",
        "        #     #get CRPS \n",
        "        #     seq_list_crps = get_CRPS_sequence(dataset=dataset_radar_sequence_val_CRPS, idx_list= crps_idx_list)\n",
        "\n",
        "        #     avg4_mean, avg16_mean, max4_mean,max16_mean, avg4_std, avg16_std, max4_std, max16_std = get_CRPS(\n",
        "        #             test_list = seq_list_crps,\n",
        "        #             rgb_grayscale = config[\"rgb_grayscale\"],\n",
        "        #             img_out_size = config[\"img_out_size\"],\n",
        "        #             sequence_length = config[\"sequence_length\"],\n",
        "        #             device = device,\n",
        "        #             sqrt_one_minus_alphas_cumprod = sqrt_one_minus_alphas_cumprod,\n",
        "        #             sqrt_recip_alphas = sqrt_recip_alphas,\n",
        "        #             posterior_variance = posterior_variance,\n",
        "        #             model = model,\n",
        "        #             T = config[\"T\"],\n",
        "        #             numb_cond = config[\"num_cond_frames\"],\n",
        "        #             betas = betas,\n",
        "        #             max_prec_val = config[\"max_prec_val\"],\n",
        "        #             cond_emb_model = cond_emb_model,\n",
        "        #     )\n",
        "        #     avg_4_crps_mean.append(avg4_mean)\n",
        "        #     avg_16_crps_mean.append(avg16_mean)\n",
        "        #     max_4_crps_mean.append(max4_mean)\n",
        "        #     max_16_crps_mean.append(max16_mean)\n",
        "            \n",
        "        #     avg_4_crps_std.append(avg4_std)\n",
        "        #     avg_16_crps_std.append(avg16_std)\n",
        "        #     max_4_crps_std.append(max4_std)\n",
        "        #     max_16_crps_std.append(max16_std)\n",
        "        \n",
        "        #     fig, axs = plt.subplots(1, 1, figsize=(30, 5))\n",
        "            \n",
        "        #     epoch_list = np.arange(0, len(validation_loss_list))\n",
        "        #     ax1 = plt.subplot(111)\n",
        "        #     ax1.plot(epoch_list, validation_loss_list, label='Validation loss')\n",
        "        #     ax1.plot(epoch_list, train_loss_list, label='Train loss')\n",
        "        #     ax1.set_title(f\"MSE\")\n",
        "        #     ax1.legend()\n",
        "            \n",
        "        #     ax2 = plt.subplot(132)\n",
        "        #     crps_epochs = np.arange(0, len(avg_4_crps_mean))\n",
        "        #     labels = crps_epochs*3\n",
        "        #     labels = labels.astype('str')\n",
        "\n",
        "        #     ax2.errorbar(crps_epochs, avg_4_crps_mean,avg_4_crps_std, marker='^', label='4-km aggregations')\n",
        "        #     ax2.errorbar(crps_epochs, avg_16_crps_mean,avg_16_crps_std, marker='*', label='16-km aggregations')\n",
        "        #     ax2.set_yscale('log')\n",
        "        #     ax2.set_title(f\"Pooled CRPS using the average rain rate\")\n",
        "        #     ax2.legend()\n",
        "\n",
        "        #     ax3 = plt.subplot(133)\n",
        "        #     ax3.errorbar(crps_epochs, max_4_crps_mean,max_4_crps_std, marker='^', label='4-km aggregations')\n",
        "        #     ax3.errorbar(crps_epochs, max_16_crps_mean,max_16_crps_std, marker='^', label='16-km aggregations')\n",
        "        #     ax3.set_title(f\"Pooled CRPS using the maximum rain rate\")\n",
        "        #     ax3.set_yscale('log')\n",
        "        #     ax3.legend()\n",
        "\n",
        "        #     folder_path = config[\"plot_folder\"]\n",
        "        #     fig.savefig(f\"{folder_path}/MSE_epoch_{epoch}.png\")\n",
        "\n",
        "        #     plt.show()\n",
        "\n",
        "\n",
        "        # if epoch % 5 == 0:\n",
        "\n",
        "        #     if config[\"validate_on_convective\"]:\n",
        "        #         pass\n",
        "    \n",
        "        #     seq_list_plot = get_CRPS_sequence(dataset=dataset_radar_sequence_val_CRPS, idx_list= crps_idx_list)\n",
        "\n",
        "        #     sample_plot_image(\n",
        "        #         test_list=seq_list_plot,\n",
        "        #         rgb_grayscale=config[\"rgb_grayscale\"],\n",
        "        #         img_out_size=config[\"img_out_size\"],\n",
        "        #         sequence_length=config[\"sequence_length\"],\n",
        "        #         device=device,\n",
        "        #         sqrt_one_minus_alphas_cumprod=sqrt_one_minus_alphas_cumprod,\n",
        "        #         sqrt_recip_alphas=sqrt_recip_alphas,\n",
        "        #         posterior_variance=posterior_variance,\n",
        "        #         model=model,\n",
        "        #         T=config[\"T\"],\n",
        "        #         pred_ahead= config[\"prediction_time_step_ahead\"],\n",
        "        #         numb_cond = config[\"num_cond_frames\"],\n",
        "        #         betas = betas,\n",
        "        #         max_prec_val = config[\"max_prec_val\"],\n",
        "        #         epoch = epoch,\n",
        "        #         out_folder = config[\"plot_folder\"]\n",
        "        #         )\n",
        "    #set model back to training mode: \n",
        "\n",
        "    model.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBsQsB3CsDsq"
      },
      "outputs": [],
      "source": [
        "PATH = config[\"plot_folder\"]\n",
        "torch.save(model.state_dict(), f = f\"{PATH}/model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T-dwCN0oMgz",
        "outputId": "74f1f8a9-7096-4608-c869-6ac45a142534"
      },
      "outputs": [],
      "source": [
        "validation_loss_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVd0Qu_soRPI",
        "outputId": "5763405e-0a21-4bd2-ab88-981b19630702"
      },
      "outputs": [],
      "source": [
        "train_loss_list"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('ML_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "54d325ac27653bbd16399bc9890710378eb69529f792fa6d179297359bb410f6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
