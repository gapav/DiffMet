{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PgYOCQvAmvi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%pip install CRPS\n",
        "%pip install torchgeo\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "!sudo apt-get install unzip\n",
        "base = Path('/content/drive/MyDrive/ML/2023/conv_strat_dataset')\n",
        "sys.path.append(str(base))\n",
        "\n",
        "zip_path = base/\"test.zip\"\n",
        "\n",
        "\n",
        "!cp \"{zip_path}\" .\n",
        "\n",
        "!unzip -q test.zip -d \"/content\"\n",
        "\n",
        "!rm test.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Mj3BpP-QpTgC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "import datetime\n",
        "\n",
        "# import wandb\n",
        "# import CRPS.CRPS as pscore\n",
        "\n",
        "\n",
        "\n",
        "from prec_dataset import RadarPrecipitationSequence\n",
        "from radar_transforms import radar_transform\n",
        "from plotting_funcs import show_sequence\n",
        "from radar_transforms import radar_transform, reverse_transform, conditional_embedding_transform\n",
        "from fdp import fdp_sample, get_named_beta_schedule\n",
        "from unet_refr_emb_GPU_0203 import UNet_embedding\n",
        "from loss import loss_fn\n",
        "from sampler import sample_plot_image\n",
        "from helper_module import get_random_test_seq, get_CRPS_sequence\n",
        "from calc_metrics import get_CRPS\n",
        "\n",
        "config = dict(\n",
        "    img_out_size=64,\n",
        "    rgb_grayscale=1,\n",
        "    sequence_length=8,\n",
        "    max_prec_val=3.4199221045419974,\n",
        "    prediction_time_step_ahead=1,\n",
        "    frames_to_predict=1,\n",
        "    num_cond_frames=3,\n",
        "    tot_pred_ahead=4,\n",
        "    schedule=\"linear\",\n",
        "    T=1000,\n",
        "\n",
        "    root_dir=r\"/content/\",\n",
        "    validate_on_convective = False,\n",
        ")\n",
        "\n",
        "betas = get_named_beta_schedule(\n",
        "    schedule_name=config[\"schedule\"], num_diffusion_timesteps=config[\"T\"]\n",
        ")\n",
        "T = config[\"T\"]\n",
        "if config[\"schedule\"] == \"linear\":\n",
        "    alphas = 1.0 - betas\n",
        "    alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "    alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "    sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
        "    sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "    sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
        "    posterior_variance = betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_PATH = '/content/drive/MyDrive/ML/results/plots/0203_emb_conv/2023-03-02_epoch_46'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HXzTE60YAmvj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCYN_x1RpTgH"
      },
      "source": [
        "### LOAD PRE-TRAINED MODELS: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8097d8a1cb964caa8f4a7977239a893d",
            "e8aca245d0934b2591fa43aa297e0486",
            "a42724a562a346d9aa4ee4d3363d7f2a",
            "cef4237f2a7b4770be65b442b0d1e973",
            "d0222af202704a8a8bc64dcdfee36047",
            "58b4977e9c434dc6a5462261389b9b00",
            "eee699ef5e84427da586ff0c6066b225",
            "f8d0e38273214d409c1e056274833bd2",
            "5dbfc0d8dda34116998b9add11e79628",
            "26beac9ce8e04b84bf2c1765ded0c6a3",
            "40c1759e3c0e4563aa2f4fc73e487249"
          ]
        },
        "id": "KCdj8u25pTgI",
        "outputId": "ffef5ae5-9cab-46d3-aa45-85acd539e6cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://huggingface.co/torchgeo/resnet18_sentinel2_rgb_moco/resolve/main/resnet18_sentinel2_rgb_moco.pth\" to /root/.cache/torch/hub/checkpoints/resnet18_sentinel2_rgb_moco.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8097d8a1cb964caa8f4a7977239a893d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/42.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act1): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = UNet_embedding(\n",
        "    rgb_grayscale=config[\"rgb_grayscale\"], num_cond_frames=config[\"num_cond_frames\"], device=device\n",
        ")\n",
        "model.load_state_dict(torch.load(model_PATH,map_location=torch.device('cpu')))\n",
        "\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "import torch\n",
        "from torchgeo.models import resnet18, ResNet18_Weights\n",
        "\n",
        "weights = ResNet18_Weights.SENTINEL2_RGB_MOCO\n",
        "\n",
        "cond_emb_model = resnet18(weights=weights)\n",
        "cond_emb_model.eval()\n",
        "cond_emb_model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SB7j_vs4pTgJ"
      },
      "outputs": [],
      "source": [
        "dataset_20min_nowcast = RadarPrecipitationSequence(\n",
        "    root_dir=config[\"root_dir\"],\n",
        "    transform=radar_transform(max_prec_val=config[\"max_prec_val\"]),\n",
        "    emb_transform=conditional_embedding_transform(max_prec_val=config[\"max_prec_val\"]),\n",
        "    num_cond_frames=config[\"num_cond_frames\"],\n",
        "    frames_to_predict=config[\"frames_to_predict\"],\n",
        "    img_out_size=config[\"img_out_size\"],\n",
        "    prediction_time_step_ahead=config[\"prediction_time_step_ahead\"],\n",
        "    train_test_val = \"test\",\n",
        "    center_crop = True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset_20min_nowcast,\n",
        "    batch_size=6,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        ")\n",
        "# for i in range(20):\n",
        "#     idx = np.random.randint(low=0, high=1000)\n",
        "#     train_sample = dataset_20min_nowcast.__getitem__(idx)\n",
        "#     print(idx)\n",
        "#     show_sequence(train_sample, config[\"sequence_length\"], pred_ahead= config[\"prediction_time_step_ahead\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyhFHfpiAmvk"
      },
      "source": [
        "#### Metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDo4Pao3Amvl",
        "outputId": "6f514e48-7179-42d2-b304-db1716c68d0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "avg4_5 =[]\n",
        "avg4_10 =[]\n",
        "avg4_15 =[]\n",
        "avg4_20 =[]\n",
        "avg_4_crps = [avg4_5,avg4_10,avg4_15,avg4_20]\n",
        "\n",
        "avg16_5 = []\n",
        "avg16_10 = []\n",
        "avg16_15 =[]\n",
        "avg16_20 =[]\n",
        "avg_16_crps = [avg16_5,avg16_10,avg16_15,avg16_20]\n",
        "\n",
        "max4_5 =[]\n",
        "max4_10 =[]\n",
        "max4_15 =[]\n",
        "max4_20 =[]\n",
        "max_4_crps_ = [max4_5,max4_10,max4_15,max4_20]\n",
        "\n",
        "max16_5 =[]\n",
        "max16_10 =[]\n",
        "max16_15 =[]\n",
        "max16_20 =[]\n",
        "max_16_crps = [max16_5,max16_10,max16_15,max16_20]\n",
        "\n",
        "\n",
        "\n",
        "sample_size = 20\n",
        "\n",
        "preds_csi = torch.empty((sample_size,4 ,64,64))\n",
        "obs_csi = torch.empty((sample_size,4,64,64))\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "\n",
        "\n",
        "    for j in tqdm(range(sample_size)):\n",
        "        sample = dataset_20min_nowcast.__getitem__(i)\n",
        "\n",
        "        prev_frames = 3\n",
        "        img_out_size = config[\"img_out_size\"],\n",
        "        tot_pred_ahead = config[\"tot_pred_ahead\"]\n",
        "\n",
        "        pred_seq = torch.zeros((7,224,224)).to(device)\n",
        "        pred_seq_csi = torch.zeros((4,64,64))\n",
        "        cond_input = sample[1].to(device)\n",
        "        observed = sample[3].to(device)\n",
        "        obs_csi[j,:,:,:] = observed[4:8,:,:]\n",
        "        \n",
        "        pred_seq[:prev_frames,:,:] = cond_input[:prev_frames,:,:]  \n",
        "\n",
        "        # only get LWE data:\n",
        "\n",
        "        pred_seq = pred_seq[None, :, :, :]\n",
        "\n",
        "\n",
        "        for i in range(prev_frames,prev_frames+config[\"tot_pred_ahead\"]):\n",
        "            #get 4 past frames:\n",
        "            cond_frames = pred_seq[:, i-prev_frames:i, :, :]\n",
        "\n",
        "            observed_nxt_step = observed[None,i, :, :]\n",
        "\n",
        "            cond_frames = cond_frames.to(device)\n",
        "            observed_nxt_step = observed_nxt_step.to(device)\n",
        "            \n",
        "            #pred next frame n times and get crps:\n",
        "            # avg_4_crps,avg_16_crps, max_4_crps,max_16_crps = get_nowcast_20_CRPS(\n",
        "            #     cond_frames = cond_frames,\n",
        "            #     observation = observed_nxt_step, \n",
        "            #     sequence_length = config['sequence_length'],\n",
        "            #     max_prec_val = config['max_prec_val'],\n",
        "            #     betas = betas,\n",
        "            #     rgb_grayscale=1,\n",
        "            #     img_out_size=64,\n",
        "            #     device=device,\n",
        "            #     sqrt_one_minus_alphas_cumprod=sqrt_one_minus_alphas_cumprod,\n",
        "            #     sqrt_recip_alphas=sqrt_recip_alphas,\n",
        "            #     posterior_variance=posterior_variance,\n",
        "            #     model=model,\n",
        "            #     numb_of_samples = 3,\n",
        "            #     T = config['T'],\n",
        "            #     cond_emb_model = cond_emb_model\n",
        "            # )\n",
        "            \n",
        "            # avg_4_crps[i-prev_frames].append(avg_4_crps)\n",
        "            # avg_16_crps[i-prev_frames].append(avg_16_crps)\n",
        "            # max_4_crps[i-prev_frames].append(max_4_crps)\n",
        "            # max_4_crps[i-prev_frames].append(max_16_crps)\n",
        "            \n",
        "            \n",
        "            #get next image in sequence;\n",
        "            pred_next_frame = sample_next_step_pred_CSI(\n",
        "            cond_frames = cond_frames,\n",
        "            device = device,\n",
        "            sqrt_one_minus_alphas_cumprod = sqrt_one_minus_alphas_cumprod,\n",
        "            sqrt_recip_alphas = sqrt_recip_alphas,\n",
        "            posterior_variance = posterior_variance,\n",
        "            model = model,\n",
        "            T = 1000\n",
        "            betas = betas,\n",
        "            rgb_grayscale=1,\n",
        "            img_out_size=64,\n",
        "            cond_emb_model=cond_emb_model)\n",
        "\n",
        "\n",
        "            pred_next_frame_interp = F.interpolate(input = pred_next_frame, size=(224), mode=\"nearest\")\n",
        "            pred_seq[:,i,:,:] = pred_next_frame_interp\n",
        "\n",
        "            pred_seq_csi[i-prev_frames,:,:] = pred_next_frame\n",
        "            print()\n",
        "\n",
        "\n",
        "        preds_csi[j,:,:,:] = pred_seq_csi[:,:,:]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DojbJbSzRSb_"
      },
      "source": [
        "### Get CSI metrics:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbzoE5EhRRgz"
      },
      "outputs": [],
      "source": [
        "#TRANSFORM VALUES TO PRECIPIATION VALS:\n",
        "\n",
        "pred_copy = preds_csi\n",
        "pred_copy += 1\n",
        "pred_copy /= 2\n",
        "pred_copy *= config['max_prec_val']\n",
        "pred_copy **= 3\n",
        "\n",
        "obs_copy = obs_csi\n",
        "obs_copy += 1\n",
        "obs_copy /= 2\n",
        "obs_copy *= config['max_prec_val']\n",
        "obs_copy **= 3\n",
        "\n",
        "\n",
        "\n",
        "time_steps = 4\n",
        "\n",
        "csi_0_5 = torch.zeros((sample_size, time_steps))\n",
        "csi_2 = torch.zeros((sample_size, time_steps))\n",
        "csi_10 = torch.zeros((sample_size, time_steps))\n",
        "\n",
        "\n",
        "for smpl in range(sample_size):\n",
        "    pred = pred_copy[smpl,:,:,:]\n",
        "    obs = obs_copy[smpl,:,:,:]\n",
        "\n",
        "    for i in range(time_steps):\n",
        "        csi_0_5[smpl,i] = csi(predictions=pred[i], observed = obs[i], t=0.5)\n",
        "        csi_2[smpl,i] = csi(predictions=pred[i], observed = obs[i], t=2)\n",
        "        csi_10[smpl,i] = csi(predictions=pred[i], observed = obs[i], t=10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlMwUWaGWvcd"
      },
      "outputs": [],
      "source": [
        "csi_05_mean = []\n",
        "csi_05_std = []\n",
        "\n",
        "\n",
        "def plot_csi(time_steps, csi_tensor):\n",
        "    csi_mean = []\n",
        "    csi_std = []\n",
        "\n",
        "    for i in range(time_steps):\n",
        "        csi_ = csi_tensor[:,i]\n",
        "\n",
        "        csi_mean.append(csi_.mean())\n",
        "        csi_std.append(csi_.std())\n",
        "    return csi_mean, csi_std\n",
        "\n",
        "csi_05_mean, csi_05_std = plot_csi(4,csi_0_5)\n",
        "csi_2_mean, csi_2_std = plot_csi(4,csi_2)\n",
        "csi_10_mean, csi_10_std = plot_csi(4,csi_10)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(30, 5))\n",
        "\n",
        "\n",
        "ax1 = plt.subplot(131)\n",
        "ticks = np.arange(5, 21, 5)\n",
        "ax1.errorbar(ticks, csi_05_mean,csi_05_std, marker='^', label='Threshold: 0.5 mm/hr')\n",
        "ax1.set_xticks(ticks)\n",
        "ax1.set_ylim([0,1.1])\n",
        "ax1.set_xlabel('Minutes lead time')\n",
        "ax1.set_ylabel('CSI')\n",
        "ax1.legend()\n",
        "\n",
        "ax2 = plt.subplot(132)\n",
        "ticks = np.arange(5, 21, 5)\n",
        "ax2.errorbar(ticks, csi_2_mean,csi_2_std, marker='^', label='Threshold: 2 mm/hr')\n",
        "ax2.set_xticks(ticks)\n",
        "ax2.set_ylim([0,1.1])\n",
        "ax2.set_xlabel('Minutes lead time')\n",
        "ax2.set_ylabel('CSI')\n",
        "ax2.legend()\n",
        "\n",
        "ax3 = plt.subplot(133)\n",
        "ticks = np.arange(5, 21, 5)\n",
        "ax3.errorbar(ticks, csi_10_mean,csi_10_std, marker='^', label='Threshold: 10 mm/hr')\n",
        "ax3.set_xticks(ticks)\n",
        "ax3.set_ylim([0,1.1])\n",
        "ax3.set_xlabel('Minutes lead time')\n",
        "ax3.set_ylabel('CSI')\n",
        "ax3.legend()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDYCwF7OUVeB"
      },
      "outputs": [],
      "source": [
        "\n",
        "                    \n",
        "                    \n",
        "\n",
        "        #     fig, axs = plt.subplots(1, 1, figsize=(30, 5))\n",
        "            \n",
        "        #     epoch_list = np.arange(0, len(validation_loss_list))\n",
        "        #     ax1 = plt.subplot(111)\n",
        "        #     ax1.plot(epoch_list, validation_loss_list, label='Validation loss')\n",
        "        #     ax1.plot(epoch_list, train_loss_list, label='Train loss')\n",
        "        #     ax1.set_title(f\"MSE\")\n",
        "        #     ax1.legend()\n",
        "            \n",
        "        #     ax2 = plt.subplot(132)\n",
        "        #     crps_epochs = np.arange(0, len(avg_4_crps_mean))\n",
        "        #     labels = crps_epochs*3\n",
        "        #     labels = labels.astype('str')\n",
        "\n",
        "        #     ax2.errorbar(crps_epochs, avg_4_crps_mean,avg_4_crps_std, marker='^', label='4-km aggregations')\n",
        "        #     ax2.errorbar(crps_epochs, avg_16_crps_mean,avg_16_crps_std, marker='*', label='16-km aggregations')\n",
        "        #     ax2.set_yscale('log')\n",
        "        #     ax2.set_title(f\"Pooled CRPS using the average rain rate\")\n",
        "        #     ax2.legend()\n",
        "\n",
        "        #     ax3 = plt.subplot(133)\n",
        "        #     ax3.errorbar(crps_epochs, max_4_crps_mean,max_4_crps_std, marker='^', label='4-km aggregations')\n",
        "        #     ax3.errorbar(crps_epochs, max_16_crps_mean,max_16_crps_std, marker='^', label='16-km aggregations')\n",
        "        #     ax3.set_title(f\"Pooled CRPS using the maximum rain rate\")\n",
        "        #     ax3.set_yscale('log')\n",
        "        #     ax3.legend()\n",
        "\n",
        "        #     folder_path = config[\"plot_folder\"]\n",
        "        #     fig.savefig(f\"{folder_path}/MSE_epoch_{epoch}.png\")\n",
        "\n",
        "        #     plt.show()\n",
        "\n",
        "\n",
        "        # if epoch % 5 == 0:\n",
        "\n",
        "        #     if config[\"validate_on_convective\"]:\n",
        "        #         pass\n",
        "\n",
        "        #     seq_list_plot = get_CRPS_sequence(dataset=dataset_radar_sequence_val_CRPS, idx_list= crps_idx_list)\n",
        "\n",
        "        #     sample_plot_image(\n",
        "        #         test_list=seq_list_plot,\n",
        "        #         rgb_grayscale=config[\"rgb_grayscale\"],\n",
        "        #         img_out_size=config[\"img_out_size\"],\n",
        "        #         sequence_length=config[\"sequence_length\"],\n",
        "        #         device=device,\n",
        "        #         sqrt_one_minus_alphas_cumprod=sqrt_one_minus_alphas_cumprod,\n",
        "        #         sqrt_recip_alphas=sqrt_recip_alphas,\n",
        "        #         posterior_variance=posterior_variance,\n",
        "        #         model=model,\n",
        "        #         T=config[\"T\"],\n",
        "        #         pred_ahead= config[\"prediction_time_step_ahead\"],\n",
        "        #         numb_cond = config[\"num_cond_frames\"],\n",
        "        #         betas = betas,\n",
        "        #         max_prec_val = config[\"max_prec_val\"],\n",
        "        #         epoch = epoch,\n",
        "        #         out_folder = config[\"plot_folder\"]\n",
        "        #         )\n",
        "        #set model back to training mode: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEg31lqupTgJ"
      },
      "source": [
        "#### Get (ONE) 20 minute nowcast: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8ukJeB1pTgK"
      },
      "outputs": [],
      "source": [
        "# # #load seq:\n",
        "# # idx_list = [0,1]\n",
        "# # seq_list = get_20min_forecast_sequence(dataset=dataset_20min_nowcast, idx_list= idx_list)\n",
        "# #load seq:\n",
        "# from calc_metrics import get_nowcast_20_CRPS\n",
        "\n",
        "# sequence_idx = 441\n",
        "# test_sample = dataset_20min_nowcast.__getitem__(sequence_idx)\n",
        "\n",
        "# stamp_string = test_sample[3]\n",
        "# time_stamp = stamp_string.split(\".\")[0]\n",
        "# time_stamp = int(time_stamp)\n",
        "# stamp_arr = [time_stamp + (i * 60 * 5) for i in range(8)]\n",
        "\n",
        "# timestamp_arr = [\n",
        "# datetime.datetime.fromtimestamp(stamp).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "# for stamp in stamp_arr\n",
        "# ]\n",
        "\n",
        "# prev_frames = 3\n",
        "# img_out_size = config[\"img_out_size\"],\n",
        "# tot_pred_ahead = config[\"tot_pred_ahead\"]\n",
        "\n",
        "# pred_seq = torch.zeros((8,224,224))\n",
        "# cond_input = test_sample[1]\n",
        "# pred_seq[:prev_frames,:,:] = cond_input[:prev_frames,:,:]  \n",
        "\n",
        "# # only get LWE data:\n",
        "\n",
        "# pred_seq = pred_seq[None, :, :, :]\n",
        "\n",
        "\n",
        "# avg4_list =[]\n",
        "# avg16_list =[]\n",
        "# max4_list =[]\n",
        "# max16_list =[]\n",
        "\n",
        "# for i in range(prev_frames,prev_frames+config[\"tot_pred_ahead\"]):\n",
        "#     #get 4 past frames:\n",
        "#     cond_frames = pred_seq[:, i-prev_frames:i, :, :]\n",
        "\n",
        "#     observed_nxt_step = lwe_data[None,i, :, :]\n",
        "\n",
        "#     cond_frames = cond_frames.to(device)\n",
        "    \n",
        "#     #pred next frame n times and get crps:\n",
        "#     avg_4_crps,avg_16_crps, max_4_crps,max_16_crps = get_nowcast_20_CRPS(\n",
        "#         cond_frames = cond_frames,\n",
        "#         observation = observed_nxt_step, \n",
        "#         sequence_length = config['sequence_length'],\n",
        "#         max_prec_val = config['max_prec_val'],\n",
        "#         betas = betas,\n",
        "#         rgb_grayscale=1,\n",
        "#         img_out_size=64,\n",
        "#         device=device,\n",
        "#         sqrt_one_minus_alphas_cumprod=sqrt_one_minus_alphas_cumprod,\n",
        "#         sqrt_recip_alphas=sqrt_recip_alphas,\n",
        "#         posterior_variance=posterior_variance,\n",
        "#         model=model,\n",
        "#         numb_of_samples = 3,\n",
        "#         T = config['T']\n",
        "#     )\n",
        "#     avg4_list.append(avg_4_crps)\n",
        "#     avg16_list.append(avg_16_crps)\n",
        "#     max4_list.append(max_4_crps)\n",
        "#     max16_list.append(max_16_crps)\n",
        "\n",
        "#     pred_next_frame = sample_next_step_pred(\n",
        "#     cond_frames = cond_frames,\n",
        "#     device = device,\n",
        "#     sqrt_one_minus_alphas_cumprod = sqrt_one_minus_alphas_cumprod,\n",
        "#     sqrt_recip_alphas = sqrt_recip_alphas,\n",
        "#     posterior_variance = posterior_variance,\n",
        "#     model = model,\n",
        "#     T = 300,\n",
        "#     betas = betas,\n",
        "#     rgb_grayscale=1,\n",
        "#     img_out_size=64)\n",
        "#     # add to sequence\n",
        "#     pred_seq[:,i,:,:] = pred_next_frame\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "# #process data to get prec. vals\n",
        "# pred_seq += 1\n",
        "# pred_seq /= 2\n",
        "# pred_seq *= config[\"max_prec_val\"]\n",
        "# pred_seq **= 3\n",
        "# max_pred_seq = torch.max(pred_seq)\n",
        "# print(f'max pred seq val: {max_pred_seq}')\n",
        "# # lwe_data  += 1\n",
        "# # lwe_data  /= 2\n",
        "# # lwe_data  *= config[\"max_prec_val\"]\n",
        "# # lwe_data  **= 3\n",
        "# max_data_val = torch.max(lwe_data )\n",
        "# print(f'max max_data_val: {max_data_val}')\n",
        "\n",
        "# max_val = max(max_pred_seq, max_data_val)\n",
        "# print(max_val)\n",
        "\n",
        "\n",
        "\n",
        "# fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
        "# fig.suptitle('Model input', fontsize=16)\n",
        "\n",
        "# ax1 = plt.subplot(141)\n",
        "# ax1.imshow((pred_seq[0, 0, :, :]), cmap=\"jet\", vmin=0, vmax=max_val)\n",
        "# ax1.set_title(f\"{timestamp_arr[0]}\")\n",
        "\n",
        "# ax2 = plt.subplot(142)\n",
        "# ax2.imshow((pred_seq[0, 1, :, :]), cmap=\"jet\", vmin=0, vmax=max_val)\n",
        "# ax2.set_title(f\"{timestamp_arr[1]}\")\n",
        "\n",
        "# ax3 = plt.subplot(143)\n",
        "# ax3.imshow((pred_seq[0, 2, :, :]), cmap=\"jet\", vmin=0, vmax=max_val)\n",
        "# ax3.set_title(f\"{timestamp_arr[2]}\")\n",
        "\n",
        "# ax4 = plt.subplot(144)\n",
        "# im4 = ax4.imshow((pred_seq[0, 3, :, :]), cmap=\"jet\", vmin=0, vmax=max_val)\n",
        "# ax4.set_title(f\"{timestamp_arr[3]}\")\n",
        "# fig.colorbar(im4)\n",
        "# plt.show()\n",
        "\n",
        "# fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
        "# fig.suptitle('Model prediction', fontsize=16)\n",
        "\n",
        "# ax5 = plt.subplot(141)\n",
        "# ax5.imshow((pred_seq[0, 4, :, :]), cmap=\"jet\", vmin=0, vmax=max_val)\n",
        "# ax5.set_title(f\"{timestamp_arr[4]}\")\n",
        "\n",
        "# ax6 = plt.subplot(142)\n",
        "# ax6.imshow((pred_seq[0, 5, :, :]), cmap=\"jet\", vmin=0, vmax=max_val)\n",
        "# ax6.set_title(f\"{timestamp_arr[5]}\")\n",
        "\n",
        "# ax7 = plt.subplot(143)\n",
        "# ax7.imshow((pred_seq[0, 6, :, :]), cmap=\"jet\", vmin=0, vmax=max_val)\n",
        "# ax7.set_title(f\"{timestamp_arr[6]}\")\n",
        "\n",
        "# ax8 = plt.subplot(144)\n",
        "# im8 = ax8.imshow((pred_seq[0, 7, :, :]), cmap=\"jet\", vmin=0, vmax=max_val)\n",
        "# ax8.set_title(f\"{timestamp_arr[7]}\")\n",
        "# fig.colorbar(im8)\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
        "# fig.suptitle('Ground truth', fontsize=16)\n",
        "\n",
        "# ax15 = plt.subplot(141)\n",
        "# ax15.imshow((lwe_data[4, :, :]), cmap=\"jet\", vmin=0, vmax=max_val)\n",
        "# ax15.set_title(f\"{timestamp_arr[4]}\")\n",
        "\n",
        "# ax16 = plt.subplot(142)\n",
        "# ax16.imshow((lwe_data[5, :, :]), cmap=\"jet\", vmin=0, vmax=max_val)\n",
        "# ax16.set_title(f\"{timestamp_arr[5]}\")\n",
        "\n",
        "# ax17 = plt.subplot(143)\n",
        "# ax17.imshow((lwe_data[6, :, :]), cmap=\"jet\", vmin=0, vmax=max_val)\n",
        "# ax17.set_title(f\"{timestamp_arr[6]}\")\n",
        "\n",
        "# ax18 = plt.subplot(144)\n",
        "# im18 = ax18.imshow((lwe_data[7, :, :]), cmap=\"jet\", vmin=0, vmax=max_val)\n",
        "# ax18.set_title(f\"{timestamp_arr[7]}\")\n",
        "# fig.colorbar(im18)\n",
        "\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "# fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "# fig.suptitle('Metrics', fontsize=16)\n",
        "\n",
        "# preds = pred_seq[0,4:,:,:]\n",
        "# obs = lwe_data[4:,:,:]\n",
        "\n",
        "# x_time = [5,10,15,20]\n",
        "# csi_2 = [csi(predictions=preds[i], observed = obs[i], t=0.5) for i in range(4)]\n",
        "# csi_5 = [csi(predictions=preds[i], observed = obs[i], t=2) for i in range(4)]\n",
        "# csi_10 = [csi(predictions=preds[i], observed = obs[i], t=10) for i in range(4)]\n",
        "\n",
        "# ax25 = plt.subplot(131)\n",
        "# ax25.plot(x_time, csi_2, marker='^', label='2 mm/hr')\n",
        "# ax25.plot(x_time, csi_5, marker='^', label='5 mm/hr')\n",
        "# ax25.plot(x_time, csi_10, marker='^', label='10 mm/hr')\n",
        "# ax25.legend()\n",
        "# ax25.set_title(f\"CSI\")\n",
        "\n",
        "\n",
        "\n",
        "# ax21 = plt.subplot(132)\n",
        "# ax21.plot(x_time, avg4_list, marker='^', label='4-km aggregations')\n",
        "# ax21.plot(x_time, avg16_list, marker='^', label='16-km aggregations')\n",
        "# ax21.legend()\n",
        "# ax21.set_title(f\"CRPS, Average pooling\")\n",
        "\n",
        "\n",
        "# ax22 = plt.subplot(133)\n",
        "# ax22.plot(x_time, max4_list, marker='^', label='4-km aggregations')\n",
        "# ax22.plot(x_time, max16_list, marker='^', label='16-km aggregations')\n",
        "# ax22.legend()\n",
        "# ax22.set_title(f\"CRPS, Max pooling\")\n",
        "\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# print(f'csi2: {csi_2}')\n",
        "# print(f'csi5: {csi_5}')\n",
        "# print(f'csi10: {csi_10}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "ML_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "54d325ac27653bbd16399bc9890710378eb69529f792fa6d179297359bb410f6"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "26beac9ce8e04b84bf2c1765ded0c6a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40c1759e3c0e4563aa2f4fc73e487249": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58b4977e9c434dc6a5462261389b9b00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dbfc0d8dda34116998b9add11e79628": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8097d8a1cb964caa8f4a7977239a893d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8aca245d0934b2591fa43aa297e0486",
              "IPY_MODEL_a42724a562a346d9aa4ee4d3363d7f2a",
              "IPY_MODEL_cef4237f2a7b4770be65b442b0d1e973"
            ],
            "layout": "IPY_MODEL_d0222af202704a8a8bc64dcdfee36047"
          }
        },
        "a42724a562a346d9aa4ee4d3363d7f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8d0e38273214d409c1e056274833bd2",
            "max": 44789785,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dbfc0d8dda34116998b9add11e79628",
            "value": 44789785
          }
        },
        "cef4237f2a7b4770be65b442b0d1e973": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26beac9ce8e04b84bf2c1765ded0c6a3",
            "placeholder": "​",
            "style": "IPY_MODEL_40c1759e3c0e4563aa2f4fc73e487249",
            "value": " 42.7M/42.7M [00:00&lt;00:00, 125MB/s]"
          }
        },
        "d0222af202704a8a8bc64dcdfee36047": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8aca245d0934b2591fa43aa297e0486": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58b4977e9c434dc6a5462261389b9b00",
            "placeholder": "​",
            "style": "IPY_MODEL_eee699ef5e84427da586ff0c6066b225",
            "value": "100%"
          }
        },
        "eee699ef5e84427da586ff0c6066b225": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8d0e38273214d409c1e056274833bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
